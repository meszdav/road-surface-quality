{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:34:27.362102Z",
     "start_time": "2020-08-31T18:34:24.790563Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, kurtosis\n",
    "import plotly.graph_objs as go\n",
    "from dash.dependencies import Input, Output, State\n",
    "import plotly.express as px\n",
    "from joblib import load\n",
    "from zipfile import ZipFile\n",
    "import base64\n",
    "import datetime\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataprocessing steps for the read data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:34:27.429049Z",
     "start_time": "2020-08-31T18:34:27.407062Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_processing(df, sample_rate):\n",
    "\n",
    "    #creating time groups in order to evenly sample the time points\n",
    "    df[\"time_groups\"] = (df[\"time\"] / sample_rate).apply(lambda x: int(x))\n",
    "\n",
    "    #dividing the time groups by 1/sample rate --> correct time stamps\n",
    "    df = df.groupby([\"time_groups\"]).mean()\n",
    "    df[\"time\"] = df.index/(1/sample_rate)\n",
    "\n",
    "#     measurementID = df[\"measurementID\"]\n",
    "\n",
    "    time = df[\"time\"]\n",
    "\n",
    "    gps_data = df[['lat', 'lon', 'height', 'velocity', 'direction', 'h_accuracy',\n",
    "                   'v_accuracy']]\n",
    "    gps_data = pd.concat([gps_data,\n",
    "                          pd.DataFrame(columns=[\"helper_1\"],\n",
    "                                       data = np.where(gps_data[\"lat\"] >0,1,0))],\n",
    "                         axis=1)\n",
    "    gps_data[\"id_gps\"] = gps_data[\"helper_1\"].cumsum()\n",
    "\n",
    "    gps_data.fillna(method=\"ffill\", inplace = True)\n",
    "    gps_data.drop(\"helper_1\", axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "    sensor_data = df[['x_lin_acc', 'y_lin_acc', 'z_lin_acc',\n",
    "                     'x_gyro', 'y_gyro','z_gyro',\n",
    "                     'x_acc', 'y_acc', 'z_acc']].interpolate(method='polynomial', order=2)\n",
    "\n",
    "#     df = pd.concat([measurementID, time,gps_data,sensor_data], axis=1).dropna()\n",
    "    df = pd.concat([time,gps_data,sensor_data], axis=1).dropna()\n",
    "\n",
    "    df[\"time_shift\"] = df[\"time\"].shift()\n",
    "\n",
    "    if round((df[\"time\"] - df[\"time_shift\"]).max(), 2) > sample_rate:\n",
    "        pass\n",
    "\n",
    "    df.drop(\"time_shift\", axis = 1, inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads the data from a zip file and does every neccessery stpes for inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:34:27.483018Z",
     "start_time": "2020-08-31T18:34:27.462030Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_measurement(archive, sample_rate):\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for c in archive.filelist:\n",
    "\n",
    "        new_df = pd.read_csv(archive.open(c))\n",
    "        new_df[\"sensor\"] = c.filename.split(\".\")[0]\n",
    "\n",
    "\n",
    "        df = pd.concat([new_df,df], axis=0)\n",
    "\n",
    "\n",
    "    df = df.pivot_table(index=\"Time (s)\", columns=\"sensor\")\n",
    "\n",
    "    df = df.reset_index().sort_values(\"Time (s)\")\n",
    "\n",
    "    new_columns = [\n",
    "                    \"time\", \"direction\", \"height\", \"h_accuracy\", \"lat\", \"lon\", \"velocity\", \"v_accuracy\",\n",
    "                    \"x_acc\", \"x_lin_acc\", \"x_gyro\",\n",
    "                    \"y_acc\", \"y_lin_acc\", \"y_gyro\",\n",
    "                    \"z_acc\", \"z_lin_acc\", \"z_gyro\"\n",
    "                ]\n",
    "\n",
    "    df.columns = [i for i in new_columns]\n",
    "\n",
    "    df =df[[\"time\",\"lat\", \"lon\", \"height\",\n",
    "            \"velocity\", \"direction\",\n",
    "            \"h_accuracy\", \"v_accuracy\",\n",
    "            \"x_lin_acc\", \"y_lin_acc\", \"z_lin_acc\",\n",
    "            \"x_gyro\", \"y_gyro\", \"z_gyro\",\n",
    "            \"x_acc\",\"y_acc\",\"z_acc\", ]]\n",
    "\n",
    "\n",
    "    df = data_processing(df, sample_rate)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:34:27.529991Z",
     "start_time": "2020-08-31T18:34:27.514000Z"
    }
   },
   "outputs": [],
   "source": [
    "def kurtosis_time(x):\n",
    "\n",
    "    return kurtosis(x, fisher=True)\n",
    "\n",
    "def rms_100(x):\n",
    "\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "\n",
    "def crest(x):\n",
    "\n",
    "    return max(abs(x))/np.sqrt(np.mean(x**2))\n",
    "\n",
    "def create_aggregated(df):\n",
    "    \"\"\"Create a aggregated dataframe in time domain\"\"\"\n",
    "    signals = ['x_lin_acc', 'y_lin_acc', \"z_lin_acc\", \n",
    "               'x_acc', 'y_acc', 'z_acc',\n",
    "               'x_gyro', 'y_gyro', 'z_gyro']\n",
    "\n",
    "    agg_df = df.groupby([\"id_gps\"]).agg({x: [\"sum\", \"mean\", \"mad\",\n",
    "                                                \"median\", \"min\", \"max\",\n",
    "                                                \"std\", \"var\", \"sem\",\n",
    "                                                \"skew\", \"quantile\",\n",
    "                                                kurtosis_time, rms_100,\n",
    "                                                crest] for x in signals})\n",
    "    \n",
    "    new_cols = []\n",
    "    \n",
    "    for k,i in enumerate(agg_df.columns):\n",
    "        \n",
    "        new_cols.append(i[0] + \"_\" +  i[1])\n",
    "\n",
    "    agg_df.columns = new_cols\n",
    "    \n",
    "    return agg_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:34:27.582959Z",
     "start_time": "2020-08-31T18:34:27.568968Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    \n",
    "    model = load(\"../models/rfc_vfinal.joblib\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:33:05.163932Z",
     "start_time": "2020-08-31T18:33:05.157937Z"
    }
   },
   "source": [
    "Classifing the data and prepare it for the plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:34:27.648921Z",
     "start_time": "2020-08-31T18:34:27.625935Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_data(df, feature_df, model):\n",
    "\n",
    "    pred = model.predict(feature_df.drop([\"id_gps\"], axis = 1))\n",
    "    \n",
    "    map_df = pd.concat([df[[\"id_gps\", \"lat\", \"lon\"]]\\\n",
    "                    .groupby([\"id_gps\"])\\\n",
    "                    .max()\\\n",
    "                    .reset_index(), \n",
    "                    pd.DataFrame({\"label\" : pred})], axis=1)\n",
    "    \n",
    "    return map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:34:27.687900Z",
     "start_time": "2020-08-31T18:34:27.676907Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    \n",
    "    df = read_measurement(\"../data/Road Surface Project 2020-08-29 11-05-47.zip\", 0.02)\n",
    "\n",
    "    feature_df = create_aggregated(df)\n",
    "    model = load_model(\"../models/rfc_vfinal.joblib\")\n",
    "    result = classify_data(feature_df,model)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dash App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Col 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:34:28.114657Z",
     "start_time": "2020-08-31T18:34:28.110658Z"
    }
   },
   "outputs": [],
   "source": [
    "description = dbc.CardBody([\"I live in Hungary, where the road surface quality is one of the worst in Europe. While I was on the road, I thought several times that it would be good to plan my trip depending on the road quality. In this case I could better enjoy the beauties of my country, and the trips would been more safe. Because of this, I decided to create a proof of concept in this topic.The goal of the proof of concept is to evaluate specific road surface measurements, and plot the road surface quality to a geographical map, only using the measurement data.The measurements have been recorded via a smart phone, and  only the accelerometer, gyroscope and gps data have been used, to classify the road surface into a quality class.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:34:28.371511Z",
     "start_time": "2020-08-31T18:34:28.360515Z"
    }
   },
   "outputs": [],
   "source": [
    "upload = dbc.CardBody([\n",
    "    dcc.Upload(\n",
    "        id='upload-data',\n",
    "        children=html.Div([\n",
    "            'Drag and Drop or ',\n",
    "            html.A('Select Files')\n",
    "        ]),\n",
    "        style={\n",
    "            'width': '100%',\n",
    "            'height': '60px',\n",
    "            'lineHeight': '60px',\n",
    "            'borderWidth': '1px',\n",
    "            'borderStyle': 'dashed',\n",
    "            'borderRadius': '5px',\n",
    "            'textAlign': 'center',\n",
    "            'margin': '10px'\n",
    "        },\n",
    "        # Allow multiple files to be uploaded\n",
    "        multiple=True\n",
    "    ),\n",
    "    html.Div(id='output-data-upload'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:34:28.543411Z",
     "start_time": "2020-08-31T18:34:28.537416Z"
    }
   },
   "outputs": [],
   "source": [
    "col1 = dbc.Card([\n",
    "    html.H1(\"Project Description\"),\n",
    "    html.P(description),\n",
    "    html.Hr(),\n",
    "    upload\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Col 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial plot in order to see something on the map if the not yet uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:37:10.460928Z",
     "start_time": "2020-08-31T18:37:10.448934Z"
    }
   },
   "outputs": [],
   "source": [
    "def basic_plot():\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig = px.scatter_mapbox( \n",
    "                            lat=[47.68333], \n",
    "                            lon=[17.63512],\n",
    "                            zoom = 12)\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "        \n",
    "    fig.layout.coloraxis.showscale = False\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:37:13.031191Z",
     "start_time": "2020-08-31T18:37:12.920240Z"
    }
   },
   "outputs": [],
   "source": [
    "map_plot = dbc.CardBody([\n",
    "    html.P(id = \"data-for-plot\"),\n",
    "    dcc.Graph(id = \"map-plot\", figure = basic_plot()), ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:37:13.166126Z",
     "start_time": "2020-08-31T18:37:13.159128Z"
    }
   },
   "outputs": [],
   "source": [
    "col2 = map_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:38:26.956126Z",
     "start_time": "2020-08-31T18:38:26.917167Z"
    }
   },
   "outputs": [],
   "source": [
    "app = dash.Dash(external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "app.layout = dbc.Container(\n",
    "    [\n",
    "        html.H1(\"Classify Road Surface Data\"),\n",
    "        html.Hr(),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(col1, md=4),\n",
    "                dbc.Col(col2, md=8),\n",
    "            ],\n",
    "            align=\"center\",\n",
    "        ),\n",
    "    ],\n",
    "    fluid=True,\n",
    ")\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"map-plot\", \"figure\"),\n",
    "  [Input('upload-data', 'contents')],\n",
    "  [State('upload-data', 'filename'),\n",
    "   State('upload-data', 'last_modified')])\n",
    "\n",
    "def update_output(list_of_contents, list_of_names, list_of_dates):\n",
    "    \n",
    "   \n",
    "    for content, name, date in zip(list_of_contents, list_of_names, list_of_dates):\n",
    "        # the content needs to be split. It contains the type and the real content\n",
    "        content_type, content_string = content.split(',')\n",
    "        # Decode the base64 string\n",
    "        content_decoded = base64.b64decode(content_string)\n",
    "        # Use BytesIO to handle the decoded content\n",
    "        zip_str = io.BytesIO(content_decoded)\n",
    "        # Now you can use ZipFile to take the BytesIO output\n",
    "        zip_obj = ZipFile(zip_str, 'r')\n",
    "\n",
    "    df = read_measurement(zip_obj,0.02)\n",
    "\n",
    "    feature_df = create_aggregated(df)\n",
    "\n",
    "    model = load_model(\"../models/rfc_vfinal.joblib\")\n",
    "\n",
    "    result = classify_data(df, feature_df,model)\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig = px.scatter_mapbox(result, \n",
    "                            lat=\"lat\", \n",
    "                            lon=\"lon\",\n",
    "                            zoom = 12, \n",
    "                            #height=300, \n",
    "                            color = \"label\", \n",
    "                            color_continuous_scale=[\"green\",\"red\"])\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.layout.coloraxis.showscale = False\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T18:39:09.171207Z",
     "start_time": "2020-08-31T18:39:05.138029Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8000/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8000/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8000/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8000/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8000/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8000/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8000/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "app.run_server(debug=False, port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
